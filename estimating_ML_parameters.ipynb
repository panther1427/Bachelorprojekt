{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook presents and implements the initial ideas of the estimation in ML Factor Analysis. The functions were later added to `utils.py`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Estimating $\\hat\\lambda$ and $\\hat\\Psi$ in the maximum likelihood Factor Analysis Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_factor_model(loadings, specific_variance, mu, nsim=1, verbose=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "        loadings:           (p, k) matrix\n",
    "        specific_variance:  (p, p) diagonal matrix, with specific variances on diagonals\n",
    "        mu:                 (p, 1) vector of means\n",
    "        nsim:               How many observations should be simulated\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "        (n, p) matrix of observations from the specified factor model\n",
    "\n",
    "    \"\"\"\n",
    "    k = loadings.shape[1]\n",
    "    p = specific_variance.shape[0]\n",
    "    if verbose:\n",
    "        print(f\"{k=} {p=}\")\n",
    "\n",
    "    X = []\n",
    "    for _ in range(nsim):\n",
    "        factor_vector = np.random.multivariate_normal(np.zeros(k), np.eye(k))\n",
    "        u = np.random.multivariate_normal(np.zeros(p), np.diag(specific_variance))\n",
    "\n",
    "        X.append(loadings @ factor_vector + u + mu)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to minimize:\n",
    "$$\n",
    "tr((\\hat{\\Lambda}\\hat{\\Lambda}' + \\Psi)^{-1} S) - log(|(\\hat{\\Lambda}\\hat{\\Lambda}' + \\Psi)^{-1} S|) \\quad \\text{w.r.t. $\\Psi$}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step:\n",
    "1. Calculate $S^* = \\Psi^{-1/2} S \\Psi^{-1/2}$, $S^* = \\Gamma \\Theta \\Gamma'$\n",
    "2. Get eigenvectors $\\gamma_{(i)}$ and values, $\\theta_i$\n",
    "3. Now $\\Lambda^*$ has columns $c_i \\gamma_i{(i)}, \\quad c_i = \\sqrt{\\max(\\theta_i - 1, 0)}$\n",
    "4. $\\hat\\Lambda = \\Psi^{1/2} \\Lambda^*$\n",
    "5. Calculate the object function $\\text{tr}((\\hat\\Lambda \\hat\\Lambda' + \\Psi)^{-1} S) - log(|(\\hat\\Lambda \\hat\\Lambda' + \\Psi)^{-1}S|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 p=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.9200258 , 19.28934412, 28.78413474, 42.03826513, 52.36085071],\n",
       "       [ 6.86836933, 16.2209485 , 26.31668071, 34.44290849, 45.62596067],\n",
       "       [ 6.2821622 , 15.82438986, 25.47848701, 36.32129902, 45.9620475 ],\n",
       "       ...,\n",
       "       [12.09127338, 21.98839508, 35.35280837, 40.87600116, 52.40441897],\n",
       "       [ 9.26148643, 21.74310034, 27.03230995, 39.87741989, 50.7011847 ],\n",
       "       [ 9.80686983, 18.65725894, 21.95390689, 38.12839992, 48.90860892]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "loadings = np.array([[2, 2, 2, 2, 2]]).T\n",
    "specific_variance = np.array([2, 2, 10, 1, 1])\n",
    "mu = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "X = sim_factor_model(loadings, specific_variance, mu, nsim=10**4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate $S^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.cov(X.T)\n",
    "Psi = np.diag(specific_variance)\n",
    "Psi_sq_inv = np.linalg.inv(Psi ** 0.5)\n",
    "S_star = Psi_sq_inv @ S @ Psi_sq_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get eigenvectors and eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval, eigvec = np.linalg.eig(S_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construct $\\Lambda^*$.\n",
    "\n",
    "Here we must choose k. Lets choose k = 1, like the underlying model that generated the data. (the `loadings` used to simulate is (5, 1) = (p, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.45884803, -1.44679443, -0.66171187, -2.04331882, -2.04910301])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_star = max(eigval[0] - 1, 0) ** 0.5 * eigvec[:,0]\n",
    "lambda_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Contstruct $\\hat\\Lambda = \\Psi^{1/2} \\Lambda^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.06312268, -2.04607631, -2.09251666, -2.04331882, -2.04910301])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_hat = Psi ** 0.5 @ lambda_star\n",
    "lambda_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate $\\text{tr}((\\hat\\Lambda \\hat\\Lambda' + \\Psi)^{-1} S) - log(|(\\hat\\Lambda \\hat\\Lambda' + \\Psi)^{-1}S|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.770666173787942"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal = np.linalg.inv(lambda_hat @ lambda_hat + Psi) @ S\n",
    "result = np.trace(internal) - np.log(np.linalg.det(internal))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done this, lets construct a function that takes an arbitrary (D, 1) array of specific variances and calculates the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective(specific_variance, X_data):\n",
    "    # Step 1\n",
    "    S = np.cov(X_data.T)\n",
    "    Psi = np.diag(specific_variance)\n",
    "    Psi_sq_inv = np.linalg.inv(Psi ** 0.5)\n",
    "    S_star = Psi_sq_inv @ S @ Psi_sq_inv\n",
    "\n",
    "    # Step 2\n",
    "    eigval, eigvec = np.linalg.eig(S_star)\n",
    "\n",
    "    # Step 3\n",
    "    lambda_star = max(eigval[0] - 1, 0) ** 0.5 * eigvec[:,0]\n",
    "\n",
    "    # Step 4\n",
    "    lambda_hat = Psi ** 0.5 @ lambda_star\n",
    "\n",
    "    # Step 5\n",
    "    internal = np.linalg.inv(lambda_hat @ lambda_hat.T + Psi) @ S\n",
    "    result = np.trace(internal) - np.log(np.linalg.det(internal))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.770666173787942"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_variance = np.array([2, 2, 10, 1, 1])\n",
    "calculate_objective(specific_variance, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches our manual step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets minimize the objective function. Note that the minimization algorithm works best with variables in $\\R$, however $\\psi_{ii} \\geq 0$. We circumvent this by optimizing with $\\alpha_i \\in \\R \\rightarrow \\psi_{ii} = \\exp(\\alpha_i) \\in [0, \\infty [$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_guess = np.array([2, 2, 10, 1, 1])\n",
    "problem = minimize(fun=lambda x: calculate_objective(np.exp(x), X_data=X),\n",
    "                   x0=x_0_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.07843272,  2.05732084, 10.04731862,  1.00318627,  1.00896644])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi_hat = np.exp(problem.x)\n",
    "psi_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple change in step 3 lets us add the option to specify k number of factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective(specific_variance, X_data, k):\n",
    "    # Step 1\n",
    "    S = np.cov(X_data.T)\n",
    "    Psi = np.diag(specific_variance)\n",
    "    Psi_sq_inv = np.linalg.inv(Psi ** 0.5)\n",
    "    S_star = Psi_sq_inv @ S @ Psi_sq_inv\n",
    "\n",
    "    # Step 2\n",
    "    eigval, eigvec = np.linalg.eig(S_star)\n",
    "\n",
    "    # Step 3\n",
    "    lambda_star = []\n",
    "    for i in range(k):\n",
    "        lambda_star.append(max(eigval[i] - 1, 0) ** 0.5 * eigvec[:,i])\n",
    "    lambda_star = np.array(lambda_star).T\n",
    "\n",
    "    # Step 4\n",
    "    lambda_hat = Psi ** 0.5 @ lambda_star\n",
    "\n",
    "    # Step 5\n",
    "    internal = np.linalg.inv(lambda_hat @ lambda_hat.T + Psi) @ S\n",
    "    result = np.trace(internal) - np.log(np.linalg.det(internal))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some data that actually has k = 2 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2 p=5\n"
     ]
    }
   ],
   "source": [
    "loadings = np.array([[2, 2, 2, 2, 2],\n",
    "                     [1, 1, 0, -1, -1]]).T\n",
    "specific_variance = np.array([2, 2, 10, 1, 1])\n",
    "mu = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "X = sim_factor_model(loadings, specific_variance, mu, nsim=10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 5.000031822293619\n",
       "        x: [ 6.326e-01  7.364e-01  2.302e+00 -5.109e-02  3.294e-02]\n",
       "      nit: 25\n",
       "      jac: [ 1.609e-06 -1.073e-06 -2.980e-07 -1.192e-06  1.073e-06]\n",
       " hess_inv: [[ 2.390e+01 -1.881e+01 ...  4.766e+00 -4.207e+00]\n",
       "            [-1.881e+01  1.774e+01 ... -4.197e+00  3.801e+00]\n",
       "            ...\n",
       "            [ 4.766e+00 -4.197e+00 ...  4.191e+01 -3.562e+01]\n",
       "            [-4.207e+00  3.801e+00 ... -3.562e+01  3.378e+01]]\n",
       "     nfev: 174\n",
       "     njev: 29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0_guess = np.array([2, 2, 10, 1, 1])\n",
    "problem = minimize(fun=lambda x: calculate_objective(np.exp(x), X_data=X, k=2),\n",
    "         x0=x_0_guess)\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then estimates are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated psi: \n",
      "[[1.88248212 0.         0.         0.         0.        ]\n",
      " [0.         2.08845499 0.         0.         0.        ]\n",
      " [0.         0.         9.98945812 0.         0.        ]\n",
      " [0.         0.         0.         0.95019627 0.        ]\n",
      " [0.         0.         0.         0.         1.0334897 ]]\n",
      "\n",
      "Estimated lambda:\n",
      "[[-1.77254165 -1.40832441]\n",
      " [-1.77151525 -1.35083897]\n",
      " [-1.95054833 -0.39189105]\n",
      " [-2.17857421  0.59117534]\n",
      " [-2.16727003  0.56890184]]\n"
     ]
    }
   ],
   "source": [
    "psi_hat = np.diag(np.exp(problem.x))\n",
    "\n",
    "k = 2\n",
    "S = np.cov(X.T)\n",
    "Psi_sq_inv = np.linalg.inv(psi_hat ** 0.5)\n",
    "S_star = Psi_sq_inv @ S @ Psi_sq_inv\n",
    "eigval, eigvec = np.linalg.eig(S_star)\n",
    "lambda_star = []\n",
    "for i in range(2):\n",
    "    lambda_star.append(max(eigval[i] - 1, 0) ** 0.5 * eigvec[:,i])\n",
    "lambda_star = np.array(lambda_star).T\n",
    "lambda_hat = psi_hat ** 0.5 @ lambda_star\n",
    "\n",
    "print(\"Estimated psi: \", psi_hat, \n",
    "      \"\",\n",
    "      \"Estimated lambda:\", lambda_hat,\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
